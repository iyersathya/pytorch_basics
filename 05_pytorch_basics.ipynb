{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Pytorch basics\n",
    "   This tutorial is based on https://github.com/yunjey/pytorch-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T16:42:48.106895Z",
     "start_time": "2018-08-08T16:42:48.102905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You are using pytorch version 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(f' You are using pytorch version {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([[ 0.5786,  2.3931, -0.4230,  0.1488],\n",
      "        [-1.2989, -0.3657,  0.3460, -0.8806],\n",
      "        [-0.9821,  1.3491,  0.0681, -0.9863],\n",
      "        [ 1.3468, -0.4600,  0.6631, -1.0717]])\n",
      "tensor([[ 0.5786,  2.3931, -0.4230,  0.1488, -1.2989, -0.3657,  0.3460, -0.8806,\n",
      "         -0.9821,  1.3491,  0.0681, -0.9863,  1.3468, -0.4600,  0.6631, -1.0717]])\n"
     ]
    }
   ],
   "source": [
    "# create a basic rank 1 tensor\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "print(x.size())\n",
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "# flatten x\n",
    "x = x.view(-1,16)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run x = 2.0\n",
      "First run w = 1.0\n",
      "First run b = 1.0\n",
      "Second run x = 4.0\n",
      "Second run w = 2.0\n",
      "Second run b = 2.0\n",
      "Third run x = 2.0\n",
      "Third run w = 1.0\n",
      "Third run b = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(f'First run x = {x.grad}')    # x.grad = 4\n",
    "print(f'First run w = {w.grad}')    # w.grad = 1 \n",
    "print(f'First run b = {b.grad}')    # b.grad = 1 \n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "print(f'Second run x = {x.grad}')    # x.grad = 4\n",
    "print(f'Second run w = {w.grad}')    # w.grad = 1 \n",
    "print(f'Second run b = {b.grad}')    # b.grad = 1 \n",
    "\n",
    "# Clear the grads manually.\n",
    "x.grad.data.zero_()\n",
    "w.grad.data.zero_()\n",
    "b.grad.data.zero_()\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "print(f'Third run x = {x.grad}')    # x.grad = 4\n",
    "print(f'Third run w = {w.grad}')    # w.grad = 1 \n",
    "print(f'Third run b = {b.grad}')    # b.grad = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic autograd example 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=torch.Size([10, 3])\n",
      "y=torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors of shape (10, 3) and (10, 2).\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "print(f'x={x.shape}')\n",
    "print(f'y={y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.2696,  0.1097, -0.0469],\n",
      "        [-0.1439, -0.0599, -0.1614]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.4313, -0.0888], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build loss function and optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass.\n",
    "for i in range(0,10,1):\n",
    "    pred = linear(x)\n",
    "    # Compute loss.\n",
    "    loss = criterion(pred, y)\n",
    "    print('loss: ', loss.item())\n",
    "    # Backward pass.\n",
    "    loss.backward()\n",
    "    # Print out the gradients.\n",
    "    print ('dL/dw: ', linear.weight.grad) \n",
    "    print ('dL/db: ', linear.bias.grad)\n",
    "    # 1-step gradient descent.\n",
    "    optimizer.step()\n",
    "    # You can also perform gradient descent at the low level.\n",
    "    # linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "    # linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from numpy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array.\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "# Convert the torch tensor to a numpy array.\n",
    "z = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
